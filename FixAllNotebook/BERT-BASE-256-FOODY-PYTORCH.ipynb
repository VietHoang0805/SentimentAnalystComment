{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"25bec108-95a4-417b-aff6-8eafe5a5e96c","cell_type":"code","source":"!gdown 18ZT8T7cUHvHNqoe_aZiDslR07lodEOK_\n!unzip sentiment.zip\n!rm sentiment.zip \n!ls","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-26T06:38:26.510639Z","iopub.execute_input":"2025-04-26T06:38:26.511316Z","iopub.status.idle":"2025-04-26T06:38:44.972530Z","shell.execute_reply.started":"2025-04-26T06:38:26.511293Z","shell.execute_reply":"2025-04-26T06:38:44.971578Z"}},"outputs":[{"name":"stdout","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=18ZT8T7cUHvHNqoe_aZiDslR07lodEOK_\nFrom (redirected): https://drive.google.com/uc?id=18ZT8T7cUHvHNqoe_aZiDslR07lodEOK_&confirm=t&uuid=002299f5-b722-4652-b4b1-c03d06b907cf\nTo: /kaggle/working/sentiment.zip\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 672M/672M [00:07<00:00, 85.1MB/s]\nArchive:  sentiment.zip\n  inflating: multi_cased_L-12_H-768_A-12/vocab.txt  \n  inflating: multi_cased_L-12_H-768_A-12/bert_config.json  \n  inflating: multi_cased_L-12_H-768_A-12/bert_model.ckpt.meta  \n  inflating: multi_cased_L-12_H-768_A-12/bert_model.ckpt.index  \n  inflating: NTC_SV/NTC_SV_test.csv  \n  inflating: NTC_SV/NTC_SV_train.csv  \n  inflating: multi_cased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \nmulti_cased_L-12_H-768_A-12  NTC_SV\n","output_type":"stream"}],"execution_count":1},{"id":"da82608b-679f-4ea0-9329-e6d42a63dff8","cell_type":"code","source":"#wandb ()\nfrom kaggle_secrets import UserSecretsClient\nimport wandb\nuser_secrets = UserSecretsClient()\n\nmy_secret = user_secrets.get_secret(\"bertbase-2\") \n\nwandb.login(key=my_secret)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T06:38:44.974091Z","iopub.execute_input":"2025-04-26T06:38:44.974326Z","iopub.status.idle":"2025-04-26T06:38:53.128863Z","shell.execute_reply.started":"2025-04-26T06:38:44.974306Z","shell.execute_reply":"2025-04-26T06:38:53.128134Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstorknguyen-286\u001b[0m (\u001b[33mstorknguyen-286-university-system-of-georgia\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":2},{"id":"292e2bae","cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer, BertModel\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom safetensors.torch import save_file\nimport os\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T06:38:53.129817Z","iopub.execute_input":"2025-04-26T06:38:53.130328Z","iopub.status.idle":"2025-04-26T06:39:16.614501Z","shell.execute_reply.started":"2025-04-26T06:38:53.130303Z","shell.execute_reply":"2025-04-26T06:39:16.613737Z"}},"outputs":[{"name":"stderr","text":"2025-04-26 06:39:05.905599: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745649546.089689      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745649546.139428      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"id":"86fff22d","cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T06:39:16.615540Z","iopub.execute_input":"2025-04-26T06:39:16.616223Z","iopub.status.idle":"2025-04-26T06:39:16.620608Z","shell.execute_reply.started":"2025-04-26T06:39:16.616197Z","shell.execute_reply":"2025-04-26T06:39:16.619893Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":4},{"id":"0282ba67","cell_type":"code","source":"SEQ_LEN = 256\nBATCH_SIZE = 16\nEPOCHS = 10\nLR = 2e-5\nSAVE_EVERY = 2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T06:39:16.623291Z","iopub.execute_input":"2025-04-26T06:39:16.623703Z","iopub.status.idle":"2025-04-26T06:39:16.682112Z","shell.execute_reply.started":"2025-04-26T06:39:16.623685Z","shell.execute_reply":"2025-04-26T06:39:16.681252Z"}},"outputs":[],"execution_count":5},{"id":"6f12ac83","cell_type":"code","source":"data = pd.read_csv(\"/kaggle/working/NTC_SV/NTC_SV_train.csv\").dropna()\ntexts = data[\"review\"].tolist()\nlabels = LabelEncoder().fit_transform(data[\"label\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T06:39:16.682904Z","iopub.execute_input":"2025-04-26T06:39:16.683189Z","iopub.status.idle":"2025-04-26T06:39:17.259722Z","shell.execute_reply.started":"2025-04-26T06:39:16.683169Z","shell.execute_reply":"2025-04-26T06:39:17.259194Z"}},"outputs":[],"execution_count":6},{"id":"b366c8dd","cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T06:39:17.260440Z","iopub.execute_input":"2025-04-26T06:39:17.260690Z","iopub.status.idle":"2025-04-26T06:39:18.451564Z","shell.execute_reply.started":"2025-04-26T06:39:17.260668Z","shell.execute_reply":"2025-04-26T06:39:18.450944Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef345bb9e88b42cf9f84b59c236962d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"224623877d6041c297c78ea2aa07fa63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f268a0682e1c41cabfc8a758f3e3fdf8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e5a0b406e8747ee962711b46485e535"}},"metadata":{}}],"execution_count":7},{"id":"94fc395d","cell_type":"code","source":"class FoodyDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        encoding = self.tokenizer(\n            self.texts[idx],\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_len,\n            return_tensors='pt'\n        )\n        return {\n            'input_ids': encoding['input_ids'].squeeze(0),\n            'attention_mask': encoding['attention_mask'].squeeze(0),\n            'label': torch.tensor(self.labels[idx], dtype=torch.long)\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T06:39:18.452293Z","iopub.execute_input":"2025-04-26T06:39:18.452495Z","iopub.status.idle":"2025-04-26T06:39:18.457868Z","shell.execute_reply.started":"2025-04-26T06:39:18.452471Z","shell.execute_reply":"2025-04-26T06:39:18.457122Z"}},"outputs":[],"execution_count":8},{"id":"33afba5f","cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(texts, labels, test_size=0.15, random_state=42)\ntrain_dataset = FoodyDataset(X_train, y_train, tokenizer, SEQ_LEN)\nval_dataset = FoodyDataset(X_val, y_val, tokenizer, SEQ_LEN)\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T06:39:18.458628Z","iopub.execute_input":"2025-04-26T06:39:18.458881Z","iopub.status.idle":"2025-04-26T06:39:18.486740Z","shell.execute_reply.started":"2025-04-26T06:39:18.458865Z","shell.execute_reply":"2025-04-26T06:39:18.486241Z"}},"outputs":[],"execution_count":9},{"id":"99bb1e28","cell_type":"code","source":"test = pd.read_csv(\"/kaggle/working/NTC_SV/NTC_SV_test.csv\").dropna()\ndata_test = test[\"review\"].tolist()\nlabel_test = LabelEncoder().fit(test[\"label\"]).transform(test[\"label\"])\ntest_dataset = FoodyDataset(data_test, label_test, tokenizer, SEQ_LEN)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T06:39:18.487421Z","iopub.execute_input":"2025-04-26T06:39:18.487701Z","iopub.status.idle":"2025-04-26T06:39:18.637677Z","shell.execute_reply.started":"2025-04-26T06:39:18.487674Z","shell.execute_reply":"2025-04-26T06:39:18.637069Z"}},"outputs":[],"execution_count":10},{"id":"4419aaf2","cell_type":"code","source":"class BERTClassifier(nn.Module):\n    def __init__(self, num_classes=3):\n        super().__init__()\n        self.bert = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n        self.dropout = nn.Dropout(0.3)\n        self.fc = nn.Linear(768, num_classes)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.pooler_output\n        x = self.dropout(pooled_output)\n        return self.fc(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T06:39:18.638347Z","iopub.execute_input":"2025-04-26T06:39:18.638543Z","iopub.status.idle":"2025-04-26T06:39:18.643598Z","shell.execute_reply.started":"2025-04-26T06:39:18.638528Z","shell.execute_reply":"2025-04-26T06:39:18.642750Z"}},"outputs":[],"execution_count":11},{"id":"f62d25a9-6519-4821-b2b9-320ba6c63473","cell_type":"code","source":"!pip install huggingface_hub[hf_xet]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T06:39:18.644290Z","iopub.execute_input":"2025-04-26T06:39:18.644506Z","iopub.status.idle":"2025-04-26T06:39:24.565667Z","shell.execute_reply.started":"2025-04-26T06:39:18.644491Z","shell.execute_reply":"2025-04-26T06:39:24.564928Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub[hf_xet] in /usr/local/lib/python3.11/dist-packages (0.30.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (2025.3.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (4.13.1)\nCollecting hf-xet>=0.1.4 (from huggingface_hub[hf_xet])\n  Downloading hf_xet-1.0.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (494 bytes)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (2025.1.31)\nDownloading hf_xet-1.0.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (54.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: hf-xet\nSuccessfully installed hf-xet-1.0.5\n","output_type":"stream"}],"execution_count":12},{"id":"398f590d","cell_type":"code","source":"model = BERTClassifier(num_classes=len(set(labels))).to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=LR)\ncriterion = nn.CrossEntropyLoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T06:39:24.566619Z","iopub.execute_input":"2025-04-26T06:39:24.566825Z","iopub.status.idle":"2025-04-26T06:39:28.031712Z","shell.execute_reply.started":"2025-04-26T06:39:24.566805Z","shell.execute_reply":"2025-04-26T06:39:28.031126Z"}},"outputs":[{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7440799fe66427d9a8c7ead463a5fa7"}},"metadata":{}}],"execution_count":13},{"id":"19d41ca7","cell_type":"code","source":"os.makedirs(\"checkpoints\", exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T06:39:28.034948Z","iopub.execute_input":"2025-04-26T06:39:28.035164Z","iopub.status.idle":"2025-04-26T06:39:28.039163Z","shell.execute_reply.started":"2025-04-26T06:39:28.035149Z","shell.execute_reply":"2025-04-26T06:39:28.038382Z"}},"outputs":[],"execution_count":14},{"id":"cecac62e-4669-4294-ace8-a6900fa76717","cell_type":"code","source":"import wandb\n\n# Khá»Ÿi táº¡o wandb\nwandb.init(project=\"bert-base-2\", name=f\"run_epoch_{EPOCHS}\", config={\n    \"epochs\": EPOCHS,\n    \"model\": \"bert-base\",\n    \"save_every\": SAVE_EVERY,\n    \"optimizer\": str(optimizer),\n    \"loss\": str(criterion),\n    \"batch_size\": BATCH_SIZE,\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T06:39:28.039924Z","iopub.execute_input":"2025-04-26T06:39:28.040272Z","iopub.status.idle":"2025-04-26T06:39:35.004343Z","shell.execute_reply.started":"2025-04-26T06:39:28.040248Z","shell.execute_reply":"2025-04-26T06:39:35.003623Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250426_063928-ojkwicww</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/storknguyen-286-university-system-of-georgia/bert-base-2/runs/ojkwicww' target=\"_blank\">run_epoch_10</a></strong> to <a href='https://wandb.ai/storknguyen-286-university-system-of-georgia/bert-base-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/storknguyen-286-university-system-of-georgia/bert-base-2' target=\"_blank\">https://wandb.ai/storknguyen-286-university-system-of-georgia/bert-base-2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/storknguyen-286-university-system-of-georgia/bert-base-2/runs/ojkwicww' target=\"_blank\">https://wandb.ai/storknguyen-286-university-system-of-georgia/bert-base-2/runs/ojkwicww</a>"},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/storknguyen-286-university-system-of-georgia/bert-base-2/runs/ojkwicww?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7aa0e91d7f50>"},"metadata":{}}],"execution_count":15},{"id":"185b167f","cell_type":"code","source":"import wandb\nfrom tqdm import tqdm\nfrom safetensors.torch import save_file\nfrom sklearn.metrics import accuracy_score\n\ndef train_model(model, train_loader, optimizer, criterion, EPOCHS, SAVE_EVERY, save_dir, device):\n    # Khá»Ÿi táº¡o wandb\n    wandb.init(project=\"bert-rcnn\", config={\n        \"epochs\": EPOCHS,\n        \"batch_size\": train_loader.batch_size,\n        \"optimizer\": str(optimizer),\n        \"loss_fn\": str(criterion),\n    })\n\n    global_step = 0\n\n    for epoch in range(EPOCHS):\n        model.train()\n        total_loss = 0\n        all_preds = []\n        all_labels = []\n\n        loop = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n\n        for i, batch in loop:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n\n            optimizer.zero_grad()\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n            preds = torch.argmax(outputs, dim=1)\n            batch_acc = (preds == labels).sum().item() / labels.size(0)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n            # Log tá»«ng batch\n            wandb.log({\n                \"batch_loss\": loss.item(),\n                \"step\": global_step\n            })\n\n            global_step += 1\n            loop.set_postfix(batch_loss=loss.item(), batch_acc=batch_acc)\n\n        # TÃ­nh vÃ  log trung bÃ¬nh theo epoch\n        epoch_loss = total_loss / len(train_loader)\n        epoch_acc = accuracy_score(all_labels, all_preds)\n\n        wandb.log({\n            \"loss\": epoch_loss,\n            \"accuracy\": epoch_acc,\n            \"epoch\": epoch + 1\n        })\n\n        print(f\"âœ… Epoch {epoch+1}: Loss = {epoch_loss:.4f}, Accuracy = {epoch_acc:.4f}\")\n\n        # LÆ°u checkpoint náº¿u cáº§n\n        if (epoch + 1) % SAVE_EVERY == 0:\n            save_path = f\"{save_dir}/bert_rcnn_epoch_{epoch+1}.safetensors\"\n            save_file(model.state_dict(), save_path)\n            print(f\"ğŸ’¾ Saved checkpoint at: {save_path}\")\n            wandb.save(save_path)\n\n    wandb.finish()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T06:39:35.004943Z","iopub.execute_input":"2025-04-26T06:39:35.005174Z","iopub.status.idle":"2025-04-26T06:39:35.014386Z","shell.execute_reply.started":"2025-04-26T06:39:35.005158Z","shell.execute_reply":"2025-04-26T06:39:35.013616Z"}},"outputs":[],"execution_count":16},{"id":"931ad547","cell_type":"code","source":"train_model(\n    model=model,\n    train_loader=train_loader,\n    optimizer=optimizer,\n    criterion=criterion,\n    EPOCHS=EPOCHS,\n    SAVE_EVERY=SAVE_EVERY,\n    save_dir=\"/kaggle/working\",\n    device=device\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T06:39:35.015019Z","iopub.execute_input":"2025-04-26T06:39:35.015307Z","iopub.status.idle":"2025-04-26T09:27:21.160036Z","shell.execute_reply.started":"2025-04-26T06:39:35.015284Z","shell.execute_reply":"2025-04-26T09:27:21.159331Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2166/2166 [16:43<00:00,  2.16it/s, batch_acc=0.833, batch_loss=0.207] \n","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 1: Loss = 0.3309, Accuracy = 0.8583\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2166/2166 [16:44<00:00,  2.16it/s, batch_acc=0.833, batch_loss=0.497] \n","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 2: Loss = 0.2469, Accuracy = 0.9035\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n","output_type":"stream"},{"name":"stdout","text":"ğŸ’¾ Saved checkpoint at: /kaggle/working/bert_rcnn_epoch_2.safetensors\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2166/2166 [16:43<00:00,  2.16it/s, batch_acc=0.833, batch_loss=0.442] \n","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 3: Loss = 0.2089, Accuracy = 0.9215\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2166/2166 [16:43<00:00,  2.16it/s, batch_acc=1, batch_loss=0.154]     \n","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 4: Loss = 0.1762, Accuracy = 0.9356\nğŸ’¾ Saved checkpoint at: /kaggle/working/bert_rcnn_epoch_4.safetensors\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2166/2166 [16:43<00:00,  2.16it/s, batch_acc=1, batch_loss=0.0532]    \n","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 5: Loss = 0.1426, Accuracy = 0.9487\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2166/2166 [16:44<00:00,  2.16it/s, batch_acc=1, batch_loss=0.0121]    \n","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 6: Loss = 0.1198, Accuracy = 0.9592\nğŸ’¾ Saved checkpoint at: /kaggle/working/bert_rcnn_epoch_6.safetensors\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2166/2166 [16:44<00:00,  2.16it/s, batch_acc=1, batch_loss=0.0053]    \n","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 7: Loss = 0.0963, Accuracy = 0.9670\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2166/2166 [16:44<00:00,  2.16it/s, batch_acc=1, batch_loss=0.00683]   \n","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 8: Loss = 0.0899, Accuracy = 0.9698\nğŸ’¾ Saved checkpoint at: /kaggle/working/bert_rcnn_epoch_8.safetensors\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2166/2166 [16:42<00:00,  2.16it/s, batch_acc=1, batch_loss=0.0171]    \n","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 9: Loss = 0.0785, Accuracy = 0.9738\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2166/2166 [16:43<00:00,  2.16it/s, batch_acc=1, batch_loss=0.00811]   \n","output_type":"stream"},{"name":"stdout","text":"âœ… Epoch 10: Loss = 0.0647, Accuracy = 0.9791\nğŸ’¾ Saved checkpoint at: /kaggle/working/bert_rcnn_epoch_10.safetensors\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>â–â–„â–…â–…â–†â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>batch_loss</td><td>â–ˆâ–„â–„â–‚â–ƒâ–ƒâ–ƒâ–„â–‡â–„â–ƒâ–‚â–â–‚â–…â–‚â–†â–„â–ƒâ–‚â–‡â–â–ˆâ–â–â–â–â–‚â–â–â–â–â–â–†â–‚â–â–â–…â–„â–</td></tr><tr><td>epoch</td><td>â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ</td></tr><tr><td>loss</td><td>â–ˆâ–†â–…â–„â–ƒâ–‚â–‚â–‚â–â–</td></tr><tr><td>step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.97907</td></tr><tr><td>batch_loss</td><td>0.00811</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>loss</td><td>0.06472</td></tr><tr><td>step</td><td>21659</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">run_epoch_10</strong> at: <a href='https://wandb.ai/storknguyen-286-university-system-of-georgia/bert-base-2/runs/ojkwicww' target=\"_blank\">https://wandb.ai/storknguyen-286-university-system-of-georgia/bert-base-2/runs/ojkwicww</a><br> View project at: <a href='https://wandb.ai/storknguyen-286-university-system-of-georgia/bert-base-2' target=\"_blank\">https://wandb.ai/storknguyen-286-university-system-of-georgia/bert-base-2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 5 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250426_063928-ojkwicww/logs</code>"},"metadata":{}}],"execution_count":17},{"id":"12b38b4e","cell_type":"code","source":"model.eval()\npreds, trues = [], []\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n\n        outputs = model(input_ids, attention_mask)\n        pred = torch.argmax(outputs, dim=1)\n        preds.extend(pred.cpu().numpy())\n        trues.extend(labels.cpu().numpy())\n\nprint(\"=== Test Result ===\")\nprint(classification_report(trues, preds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T09:27:21.161250Z","iopub.execute_input":"2025-04-26T09:27:21.161552Z","iopub.status.idle":"2025-04-26T09:28:44.545662Z","shell.execute_reply.started":"2025-04-26T09:27:21.161535Z","shell.execute_reply":"2025-04-26T09:28:44.544883Z"}},"outputs":[{"name":"stdout","text":"=== Test Result ===\n              precision    recall  f1-score   support\n\n           0       0.88      0.91      0.90      5000\n           1       0.90      0.88      0.89      5000\n\n    accuracy                           0.89     10000\n   macro avg       0.89      0.89      0.89     10000\nweighted avg       0.89      0.89      0.89     10000\n\n","output_type":"stream"}],"execution_count":18},{"id":"891cb835","cell_type":"code","source":"save_file(model.state_dict(), \"bert_base_foody.safetensors\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T09:28:44.546486Z","iopub.execute_input":"2025-04-26T09:28:44.546764Z","iopub.status.idle":"2025-04-26T09:28:46.294852Z","shell.execute_reply.started":"2025-04-26T09:28:44.546738Z","shell.execute_reply":"2025-04-26T09:28:46.294064Z"}},"outputs":[],"execution_count":19}]}