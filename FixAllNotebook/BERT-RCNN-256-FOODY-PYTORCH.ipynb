{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5c3306d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.7.0-cp311-cp311-win_amd64.whl.metadata (29 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from torch) (4.13.2)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Using cached torch-2.7.0-cp311-cp311-win_amd64.whl (212.5 MB)\n",
      "Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.3.2 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 sympy-1.13.3 torch-2.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Using cached numpy-2.2.5-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: colorama in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
      "  Using cached charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "Using cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Using cached numpy-2.2.5-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "Using cached regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl (102 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: urllib3, tqdm, safetensors, regex, pyyaml, numpy, idna, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed certifi-2025.1.31 charset-normalizer-3.4.1 huggingface-hub-0.30.2 idna-3.10 numpy-2.2.5 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.3 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.51.3 urllib3-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.2.3-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (2.2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from scikit-learn) (2.2.5)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.15.2-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.6.1-cp311-cp311-win_amd64.whl (11.1 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached scipy-1.15.2-cp311-cp311-win_amd64.whl (41.2 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting gradio\n",
      "  Using cached gradio-5.26.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting anyio<5.0,>=3.0 (from gradio)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Using cached fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Using cached ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.9.0 (from gradio)\n",
      "  Using cached gradio_client-1.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Using cached groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting httpx>=0.24.1 (from gradio)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from gradio) (0.30.2)\n",
      "Requirement already satisfied: jinja2<4.0 in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from gradio) (2.2.5)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Using cached orjson-3.10.16-cp311-cp311-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: packaging in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from gradio) (25.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from gradio) (2.2.3)\n",
      "Collecting pillow<12.0,>=8.0 (from gradio)\n",
      "  Using cached pillow-11.2.1-cp311-cp311-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting pydantic<2.12,>=2.0 (from gradio)\n",
      "  Using cached pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting pydub (from gradio)\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from gradio) (6.0.2)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Using cached ruff-0.11.7-py3-none-win_amd64.whl.metadata (26 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Using cached safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Using cached starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Using cached tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Using cached typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from gradio) (4.13.2)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Using cached uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from gradio-client==1.9.0->gradio) (2025.3.2)\n",
      "Collecting websockets<16.0,>=10.0 (from gradio-client==1.9.0->gradio)\n",
      "  Using cached websockets-15.0.1-cp311-cp311-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: idna>=2.8 in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Collecting sniffio>=1.1 (from anyio<5.0,>=3.0->gradio)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: certifi in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
      "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: filelock in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
      "Requirement already satisfied: requests in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<2.12,>=2.0->gradio)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic<2.12,>=2.0->gradio)\n",
      "  Using cached pydantic_core-2.33.1-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<2.12,>=2.0->gradio)\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting click>=8.0.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: colorama in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached gradio-5.26.0-py3-none-any.whl (46.9 MB)\n",
      "Using cached gradio_client-1.9.0-py3-none-any.whl (322 kB)\n",
      "Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "Using cached groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached orjson-3.10.16-cp311-cp311-win_amd64.whl (133 kB)\n",
      "Using cached pillow-11.2.1-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "Using cached pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "Using cached pydantic_core-2.33.1-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Using cached ruff-0.11.7-py3-none-win_amd64.whl (11.6 MB)\n",
      "Using cached safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Using cached starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "Using cached tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Using cached typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Using cached uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
      "Using cached ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Using cached websockets-15.0.1-cp311-cp311-win_amd64.whl (176 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pydub, websockets, typing-inspection, tomlkit, sniffio, shellingham, semantic-version, ruff, python-multipart, pydantic-core, pillow, orjson, mdurl, h11, groovy, ffmpy, click, annotated-types, aiofiles, uvicorn, pydantic, markdown-it-py, httpcore, anyio, starlette, rich, httpx, typer, safehttpx, gradio-client, fastapi, gradio\n",
      "Successfully installed aiofiles-24.1.0 annotated-types-0.7.0 anyio-4.9.0 click-8.1.8 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.26.0 gradio-client-1.9.0 groovy-0.1.2 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 markdown-it-py-3.0.0 mdurl-0.1.2 orjson-3.10.16 pillow-11.2.1 pydantic-2.11.3 pydantic-core-2.33.1 pydub-0.25.1 python-multipart-0.0.20 rich-14.0.0 ruff-0.11.7 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 sniffio-1.3.1 starlette-0.46.2 tomlkit-0.13.2 typer-0.15.2 typing-inspection-0.4.0 uvicorn-0.34.2 websockets-15.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: safetensors in h:\\sentimentanalystcomment\\fixallnotebook\\.venv\\lib\\site-packages (0.5.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "%pip install transformers\n",
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install scikit-learn\n",
    "%pip install gradio\n",
    "%pip install safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351fd146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "from safetensors.torch import save_file\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196b0c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12d0c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 256\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LR = 2e-5\n",
    "SAVE_EVERY = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216d7ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/sentimentdataset/NTC_SV/NTC_SV_train.csv\").dropna()\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(train_df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fab422",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoodyDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31e6160",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_df['review'], labels, test_size=0.15, random_state=42)\n",
    "train_dataset = FoodyDataset(X_train.tolist(), y_train, tokenizer, SEQ_LEN)\n",
    "val_dataset = FoodyDataset(X_val.tolist(), y_val, tokenizer, SEQ_LEN)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999183c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"/kaggle/input/sentimentdataset/NTC_SV/NTC_SV_test.csv\").dropna()\n",
    "test_texts = test_df['review'].tolist()\n",
    "test_labels = le.transform(test_df['label'])\n",
    "test_dataset = FoodyDataset(test_texts, test_labels, tokenizer, SEQ_LEN)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0bc511",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_RCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "        self.conv1 = nn.Conv1d(768, 256, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.rnn = nn.LSTM(256, 128, num_layers=1, bidirectional=True, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(128*2, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        with torch.no_grad():\n",
    "            bert_out = self.bert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n",
    "        x = bert_out.permute(0, 2, 1)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x, _ = self.rnn(x)\n",
    "        x = torch.mean(x, dim=1)\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5661c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT_RCNN(num_classes=len(set(labels))).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50c75fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"checkpoints\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6296ea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for batch in tqdm(dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    return total_loss / len(dataloader), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7bea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    loss, acc = train_epoch(model, train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {loss:.4f} - Accuracy: {acc:.4f}\")\n",
    "    if (epoch + 1) % SAVE_EVERY == 0:\n",
    "        save_path = f\"checkpoints/bert_rcnn_epoch{epoch+1}.safetensors\"\n",
    "        save_file(model.state_dict(), save_path)\n",
    "        print(f\"✔️ Saved checkpoint at {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448287fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "preds, trues = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        pred = torch.argmax(outputs, dim=1)\n",
    "        preds.extend(pred.cpu().numpy())\n",
    "        trues.extend(labels.cpu().numpy())\n",
    "\n",
    "print(\"=== Test Result ===\")\n",
    "print(classification_report(trues, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dee278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file(model.state_dict(), \"bert_rcnn_foody_final.safetensors\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
