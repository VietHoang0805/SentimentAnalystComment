{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f79d30eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Using cached numpy-2.2.5-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in h:\\sentimentanalystcomment\\bert-embedding-cnn\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
      "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in h:\\sentimentanalystcomment\\bert-embedding-cnn\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: colorama in h:\\sentimentanalystcomment\\bert-embedding-cnn\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
      "  Using cached charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "Using cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Using cached numpy-2.2.5-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "Using cached regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl (102 kB)\n",
      "Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: urllib3, tqdm, safetensors, regex, pyyaml, numpy, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed certifi-2025.1.31 charset-normalizer-3.4.1 filelock-3.18.0 fsspec-2025.3.2 huggingface-hub-0.30.2 idna-3.10 numpy-2.2.5 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.3 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.51.3 urllib3-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting torch\n",
      "  Using cached torch-2.6.0-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in h:\\sentimentanalystcomment\\bert-embedding-cnn\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in h:\\sentimentanalystcomment\\bert-embedding-cnn\\.venv\\lib\\site-packages (from torch) (4.13.2)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: fsspec in h:\\sentimentanalystcomment\\bert-embedding-cnn\\.venv\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Using cached torch-2.6.0-cp311-cp311-win_amd64.whl (204.2 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, MarkupSafe, jinja2, torch\n",
      "Successfully installed MarkupSafe-3.0.2 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 sympy-1.13.1 torch-2.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in h:\\sentimentanalystcomment\\bert-embedding-cnn\\.venv\\lib\\site-packages (from scikit-learn) (2.2.5)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.15.2-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.6.1-cp311-cp311-win_amd64.whl (11.1 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached scipy-1.15.2-cp311-cp311-win_amd64.whl (41.2 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in h:\\sentimentanalystcomment\\bert-embedding-cnn\\.venv\\lib\\site-packages (2.2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in h:\\sentimentanalystcomment\\bert-embedding-cnn\\.venv\\lib\\site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in h:\\sentimentanalystcomment\\bert-embedding-cnn\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in h:\\sentimentanalystcomment\\bert-embedding-cnn\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.2.3-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install transformers\n",
    "# %pip install torch\n",
    "# %pip install scikit-learn\n",
    "# %pip install numpy\n",
    "# %pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcf1ce33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T14:01:33.606686Z",
     "iopub.status.busy": "2025-04-23T14:01:33.605977Z",
     "iopub.status.idle": "2025-04-23T14:01:33.610611Z",
     "shell.execute_reply": "2025-04-23T14:01:33.609838Z",
     "shell.execute_reply.started": "2025-04-23T14:01:33.606655Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\SentimentAnalystComment\\BERT-embedding-CNN\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# BERT + RCNN với PyTorch cho bài toán phân loại văn bản FOODY\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7569065a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T14:01:40.666173Z",
     "iopub.status.busy": "2025-04-23T14:01:40.665909Z",
     "iopub.status.idle": "2025-04-23T14:01:41.392388Z",
     "shell.execute_reply": "2025-04-23T14:01:41.391651Z",
     "shell.execute_reply.started": "2025-04-23T14:01:40.666155Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1 Load dữ liệu\n",
    "train_path = \"H:/SentimentAnalystComment/BERT-embedding-CNN/NTC_SV/NTC_SV_train.csv\"\n",
    "test_path = \"H:/SentimentAnalystComment/BERT-embedding-CNN/NTC_SV/NTC_SV_test.csv\"\n",
    "df = pd.read_csv(train_path).dropna()\n",
    "df_test = pd.read_csv(test_path).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e984b93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T14:02:11.750172Z",
     "iopub.status.busy": "2025-04-23T14:02:11.749905Z",
     "iopub.status.idle": "2025-04-23T14:02:11.755708Z",
     "shell.execute_reply": "2025-04-23T14:02:11.754894Z",
     "shell.execute_reply.started": "2025-04-23T14:02:11.750153Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class FoodyDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=256):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c40f40c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T14:02:26.851447Z",
     "iopub.status.busy": "2025-04-23T14:02:26.851137Z",
     "iopub.status.idle": "2025-04-23T14:02:26.857659Z",
     "shell.execute_reply": "2025-04-23T14:02:26.856986Z",
     "shell.execute_reply.started": "2025-04-23T14:02:26.851403Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 4. Mô hình BERT + RCNN\n",
    "class BERT_RCNN(nn.Module):\n",
    "    def __init__(self, bert_model_name='bert-base-multilingual-cased', hidden_size=768, rnn_hidden=128, num_classes=3):\n",
    "        super(BERT_RCNN, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.bi_gru = nn.GRU(hidden_size, rnn_hidden, bidirectional=True, batch_first=True)\n",
    "        self.conv1d = nn.Conv1d(2 * rnn_hidden, 128, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        with torch.no_grad():\n",
    "            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        rnn_out, _ = self.bi_gru(sequence_output)\n",
    "        rnn_out = rnn_out.permute(0, 2, 1)\n",
    "        conv_out = self.relu(self.conv1d(rnn_out))\n",
    "        pooled = torch.max(conv_out, dim=2)[0]\n",
    "        return self.fc(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "441ca578",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T14:02:46.991878Z",
     "iopub.status.busy": "2025-04-23T14:02:46.991603Z",
     "iopub.status.idle": "2025-04-23T14:02:47.888215Z",
     "shell.execute_reply": "2025-04-23T14:02:47.887466Z",
     "shell.execute_reply.started": "2025-04-23T14:02:46.991859Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 5. Khởi tạo tokenizer, dataset, dataloader\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "train_dataset = FoodyDataset(df['review'].tolist(), df['label'].tolist(), tokenizer)\n",
    "test_dataset = FoodyDataset(df_test['review'].tolist(), df_test['label'].tolist(), tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3376189a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T14:02:56.763163Z",
     "iopub.status.busy": "2025-04-23T14:02:56.762891Z",
     "iopub.status.idle": "2025-04-23T14:02:57.949794Z",
     "shell.execute_reply": "2025-04-23T14:02:57.949100Z",
     "shell.execute_reply.started": "2025-04-23T14:02:56.763142Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 6. Khởi tạo mô hình, loss, optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BERT_RCNN(num_classes=len(set(df['label']))).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0efbb7a-b691-4a5c-9234-d360217b3ed8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T14:04:19.855650Z",
     "iopub.status.busy": "2025-04-23T14:04:19.854980Z",
     "iopub.status.idle": "2025-04-23T14:04:19.859505Z",
     "shell.execute_reply": "2025-04-23T14:04:19.858670Z",
     "shell.execute_reply.started": "2025-04-23T14:04:19.855620Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 7. Huấn luyện\n",
    "num_epochs = 10\n",
    "save_every = 2\n",
    "save_dir = \"checkpoints\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7acc39d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T14:04:21.878357Z",
     "iopub.status.busy": "2025-04-23T14:04:21.878073Z",
     "iopub.status.idle": "2025-04-23T14:04:30.454431Z",
     "shell.execute_reply": "2025-04-23T14:04:30.453479Z",
     "shell.execute_reply.started": "2025-04-23T14:04:21.878336Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   1%|          | 19/2548 [01:58<4:23:02,  6.24s/it, loss=0.701]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m labels = batch[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m].to(device)\n\u001b[32m     12\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m     15\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh:\\SentimentAnalystComment\\BERT-embedding-CNN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh:\\SentimentAnalystComment\\BERT-embedding-CNN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mBERT_RCNN.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask)\u001b[39m\n\u001b[32m     15\u001b[39m rnn_out, _ = \u001b[38;5;28mself\u001b[39m.bi_gru(sequence_output)\n\u001b[32m     16\u001b[39m rnn_out = rnn_out.permute(\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m conv_out = \u001b[38;5;28mself\u001b[39m.relu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnn_out\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     18\u001b[39m pooled = torch.max(conv_out, dim=\u001b[32m2\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fc(pooled)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh:\\SentimentAnalystComment\\BERT-embedding-CNN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh:\\SentimentAnalystComment\\BERT-embedding-CNN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh:\\SentimentAnalystComment\\BERT-embedding-CNN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:375\u001b[39m, in \u001b[36mConv1d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh:\\SentimentAnalystComment\\BERT-embedding-CNN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:370\u001b[39m, in \u001b[36mConv1d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    359\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv1d(\n\u001b[32m    360\u001b[39m         F.pad(\n\u001b[32m    361\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    368\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    369\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct, total = 0, 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for batch in loop:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    acc = correct / total\n",
    "    print(f\"\\n✅ Epoch {epoch+1} — Loss: {total_loss/len(train_loader):.4f} — Accuracy: {acc:.2%}\")\n",
    "\n",
    "    if (epoch + 1) % save_every == 0:\n",
    "        ckpt_path = os.path.join(save_dir, f\"bert_rcnn_epoch{epoch+1}.pth\")\n",
    "        torch.save(model.state_dict(), ckpt_path)\n",
    "        print(f\"💾 Đã lưu mô hình tại: {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631417c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = \"./bertrcnn_checkpoints\"\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962b504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(f\"{SAVE_PATH}/final_model\")\n",
    "tokenizer.save_pretrained(f\"{SAVE_PATH}/final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca6ad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc92b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"\\n📊 Độ chính xác trên tập test: {correct / total:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7208635,
     "sourceId": 11498854,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
